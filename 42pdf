#!/bin/bash

display_help() {
	cat << EOF
Usage: ./42pdf NAME/ID [OPTIONS]

Instantly download pdf's from 42

Arguments:
 NAME/ID         The name or id of the PDF to download
 find            Find and download a PDF in the database
 pack            Shows available packs

Options:
 -h, --help      Display this help message
 -b, --browser   Open the PDF in browser
 -o, --output P  Download PDF to path P
 -t, --title     Display the PDF title
 -s, --summary   Display the PDF summary
 -v, --version   Display the PDF version
 -p, --page [N]  Display content of page N
EOF
	exit 0
}

check_errors() {
	script_dir="$(dirname "$(realpath "${BASH_SOURCE[0]}")")"
	db_name=$script_dir/pdf_db.txt
	if [ "$GITHUB_ACTIONS" = "true" ]; then
		return 0
	fi
	if [ $# -gt 3 ]; then
		echo "Too many arguments"
		exit 1
	fi
	if [ -z "$1" ] || [ "$1" == "-h" ] || [ "$1" == "--help" ]; then
		display_help
	fi
	if git status | grep -q "Your branch is behind"; then
		echo "Updates avaliable, updating..."
		if ! git diff-index --quiet HEAD --; then
			echo "Restore the changes in the following repo to update"
			echo "$script_dir"
		else
			cd $script_dir ; git pull ; cd -
		fi
	fi
	if git ls-files --deleted | read -r; then
		echo "Restore the deleted files in the following repo for the script to run"
		echo "$script_dir"
		exit 1
	fi
	if ! timeout 3 ping -c 1 google.com &> /dev/null; then
		echo "Bad internet connection"
		exit 1
	fi
	if ! command -v pdftotext &> /dev/null; then
		echo "pdftotext is required but not installed. Do you want to install it now? (Ctrl+C to exit)"
		sudo apt-get update && sudo apt-get install -y poppler-utils
		if [ $? -eq 1 ]; then
			exit 0
		fi
	fi
	# if [ ! -f "$HOME/.local/bin/42pdf" ]; then
	# 	ln -s "$(realpath "$0")" "$HOME/.local/bin/42pdf"
	# fi
}

migrate_database() {
	old_db_name=old_pdf_db.txt
	if [ ! -f $old_db_name ]; then
		echo No file $old_db_name found, creating based on $db_name
		cp $db_name $old_db_name
		echo "$db_name will be cleaned in 5 seconds"
		sleep 5
		echo "1560 C Piscine" > $db_name
		return 1
	fi
	updating_started=false
	while IFS= read -r curr_line; do
		if [[ "$curr_line" == "$start_id" ]]; then
			updating_started=true
			echo Started migration from $start_id
			continue
		fi
		if [ "$updating_started" == true ]; then
			start_id=$(echo $curr_line | awk '{print $1}')
			url=https://cdn.intra.42.fr/pdf/pdf/$start_id/en.subject.pdf
			# commands to check the existance of pdf on server
			status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
			if [ "$status_code" -eq 200 ]; then
				pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
				echo "$curr_line $pdf_name" >> $db_name
			fi
		fi
	done < $old_db_name
	if [ "$updating_started" == false ]; then
		echo There is nothing to migrate
	else
		echo Everything migrated successfully
	fi
}

update_database_in_order() {
	echo Started updating from $start_id to $end_id
	for (( i=start_id; i<=end_id; i++ ))
	do
		url=https://cdn.intra.42.fr/pdf/pdf/$i/en.subject.pdf
		status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
		if [ "$status_code" -eq 200 ]; then
			pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
			echo "$i $pdf_name" >> $db_name
		fi
	done
}

update_database() {
	echo Started updating from $start_id to $end_id
	threads_num=200
	seq $start_id $end_id | xargs -P $threads_num -I {} bash -c '
		url=https://cdn.intra.42.fr/pdf/pdf/{}/en.subject.pdf
		status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
		if [ "$status_code" -eq 200 ]; then
			pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
			echo "{} $pdf_name" >> pdf_db.txt
		fi
	'
	sort -n -o $db_name $db_name
}

create_pdf_id_db_super_fast() {
	CMD=gobuster
	[ -d "$HOME/.local/bin" ] || mkdir -p "$HOME/.local/bin"
	[[ ":$PATH:" != *":$HOME/.local/bin:"* ]] && export PATH="$HOME/.local/bin:$PATH"
	if ! command -v $CMD &> /dev/null; then
		echo Downloading $CMD...
		TEMP_DIR=$(mktemp -d)
		cd $TEMP_DIR
		apt-get download $CMD > /dev/null
		dpkg -x $CMD*.deb $TEMP_DIR/$CMD
		rm $CMD*.deb
		cp $TEMP_DIR/$CMD/usr/bin/$CMD $HOME/.local/bin
		rm -rf $TEMP_DIR/$CMD
		cd - > /dev/null
		rmdir $TEMP_DIR
	fi
	# create url list for gobuster
	list_name=semi_url_db.txt
	url=/en.subject.pdf
	echo -n > $list_name
	for ((i=start_id; i<=end_id; i++)); do
		echo "$i$url" >> $list_name
	done

	threads_num=50
	pdf_id_db_name=pdf_id_db.txt
	echo Creating pdf_id_db with gobuster
	gobuster -q -n -u https://cdn.intra.42.fr/pdf/pdf -w $list_name -t $threads_num > $pdf_id_db_name

	rm $list_name
	sed -i 's/\/en\.subject\.pdf//g' $pdf_id_db_name
	sed -i 's/\///g' $pdf_id_db_name
	sort -no $pdf_id_db_name $pdf_id_db_name
}
update_database_super_fast() {
	create_pdf_id_db_super_fast

	echo Started updating from $start_id to $end_id
	threads_num=200
	cat $pdf_id_db_name | xargs -P $threads_num -I {} bash -c '
		url=https://cdn.intra.42.fr/pdf/pdf/{}/en.subject.pdf
		pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
		echo "{} $pdf_name" >> pdf_db.txt
	'
	rm $pdf_id_db_name
	sort -n -o $db_name $db_name
}

fzf_search() {
	CMD=fzf
	[ -d "$HOME/.local/bin" ] || mkdir -p "$HOME/.local/bin"
	[[ ":$PATH:" != *":$HOME/.local/bin:"* ]] && export PATH="$HOME/.local/bin:$PATH"
	if ! command -v $CMD &> /dev/null; then
		echo Downloading $CMD...
		TEMP_DIR=$(mktemp -d)
		cd $TEMP_DIR
		apt-get download $CMD > /dev/null
		dpkg -x $CMD*.deb $TEMP_DIR/$CMD
		rm $CMD*.deb
		cp $TEMP_DIR/$CMD/usr/bin/$CMD $HOME/.local/bin
		rm -rf $TEMP_DIR/$CMD
		cd - > /dev/null
		rmdir $TEMP_DIR
	fi
	pdf_name=$(cat $db_name | cut -d' ' -f2- | sort | uniq | fzf)
	if [ -z "$pdf_name" ]; then
		return 0
	else
		search_and_download_by_name "$pdf_name" "$2"
	fi
}

download_pdf_entry() {
	for curr in $(seq -w 00 $3); do
		i=0
		while [ "$entry" != "$2$curr" ]; do
			let i=i+1
			line=$(download_pdf "$1" "-e" "$i")
			entry=$(echo $line | cut -d' ' -f2-)
			# echo Returned $1 $line
		done
		download_pdf "$(echo $line | awk '{print $1}')"
		entry=$(echo $entry | tr ' ' '-' |  tr '/' '-' | sed 's/--*/-/g')
		mv "$pdf_name.subject.pdf" "c_piscine/$pdf_name.$entry.subject.pdf"
	done
}
download_pack() {
	pack_name="$2"
	case "$pack_name" in
		"c_piscine")
			echo "This is not optimized so it may take a long time"
			echo "Downloading C piscine pack..."
			mkdir -p "c_piscine"
			download_pdf_entry "C Piscine" "Shell " "01"
			download_pdf_entry "C Piscine" "Rush " "02"
			download_pdf_entry "C Piscine" "C " "13"
			;;
		"common_core")
			echo "Downloading Common Core pack..."
			mkdir -p "common_core"
			for project in "Libft" "ft_printf" "Get Next Line" "Born2beRoot" "minitalk" \
					"pipex" "push_swap" "fdf" "fract’ol" "So Long" "philosophers" "minishell" \
					"Net_Practice" "miniRT" "cub3d" "inception" "webserv" "ft_irc" "ft_transcendence"; do
				download_pdf "$project"
				mv "$pdf_name.subject.pdf" "common_core"
			done
			;&
		"cpp_modules")
			echo "Downloading C++ Modules pack..."
			mkdir -p "cpp_modules"
			for i in {00..09}; do
				download_pdf "C++ - Module $i"
				mv "$pdf_name.subject.pdf" "cpp_modules"
			done
			if [ "$pack_name" == "common_core" ]; then
				mv "cpp_modules" "common_core"
			fi
			;;
		"mysterious")
			echo "Downloading Mysterious pack..."
			download_pdf "???"
			download_pdf "β"
			download_pdf "6/2/2023"
			;;
		"all_42_pdf")
			echo "Downloading All 42 subjects pack..."
			mkdir -p "all_42_pdf"
			all_subjects=$(cat $db_name | cut -d' ' -f2- | sort | uniq)
			echo "$all_subjects" | while read -r project; do
				download_pdf "$project"
				mv "$pdf_name.subject.pdf" "all_42_pdf"
			done
			;;
		"mlx")
			git clone git@github.com:42Paris/minilibx-linux.git
			;;
		*)
			echo "Usage: ./42pdf pack <pack_name>"
			echo
			echo "Available packs:"
			echo "- cpp_modules  : C++ Modules subjects"
			echo "- common_core  : Common Core subjects"
			echo "- all_42_pdf   : Almost all 42 subjects (-1gb)" minilibx
			echo "- mysterious   : Hella sus subjects"
			echo "- mlx          : MinilibX graphics library"
			;;
	esac
}

verify_pdf() {
	if ! [[ "$1" =~ ^[0-9]+$ ]]; then
		if [ "$2" == "-e" ] && [ -n "$3" ]; then
			found_line_index=$(cat $db_name | cut -d' ' -f2- | grep -nwxi "$1" | tac | sed -n "$3p" | awk -F':' '{print $1}')
		else
			found_line_index=$(cat $db_name | cut -d' ' -f2- | grep -nwxi "$1" | tail -n 1 | awk -F':' '{print $1}')
		fi
		if [ -z "$found_line_index" ]; then
			echo "No pdf called $1 found"
			exit 1
		fi
		pdf_id=$(sed -n "${found_line_index}p" $db_name | awk '{print $1}')
		pdf_name=$(sed -n "${found_line_index}p" $db_name | cut -d' ' -f2- | tr ' ' '-' |  tr '/' '-' | sed 's/--*/-/g')
	else
		pdf_id=$1
	fi
	url=https://cdn.intra.42.fr/pdf/pdf/$pdf_id/en.subject.pdf
	status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
	if [ "$status_code" -ne 200 ]; then
		echo "Subject of id: $pdf_id isn't available"
		exit 1
	fi
}

download_pdf() {
	verify_pdf "$@"
	if [ "$2" == "-o" ] || [ "$2" == "--output" ]; then
		if [ -z "$3" ]; then
			echo "No path given"
			echo
			echo "Usage: ./42pdf NAME/ID -o <target_path>"
			exit 1
		fi
		if [ ! -d "$3" ]; then
			echo "Invalid path: $3"
			exit 1
		fi
		target_path=$3
	else
		target_path=.
	fi
	if [ -z "$2" ] || [ "$target_path" != "." ]; then
		if [[ "$1" =~ ^[0-9]+$ ]]; then
			# echo Downloaded based on ID
			curl -sfo temp.subject.pdf $url
			pdf_name=$(pdftotext -l 1 temp.subject.pdf - | head -n 1 | tr ' ' '-' |  tr '/' '-' | sed 's/--*/-/g')
			mv temp.subject.pdf $target_path/$pdf_name.subject.pdf
		else
			# echo Downloaded based on NAME
			curl -sfo $target_path/$pdf_name.subject.pdf $url
		fi
		echo "Downloaded $pdf_name subject of id: $pdf_id"
		return 0
	fi
	handle_arguments "$@"
}
handle_arguments() {
	case "$2" in
		--browser|-b)
			open $url
			;;
		--title|-t)
			curl -sf $url | pdftotext -l 1 - - | head -n 1
			;;
		--summary|-s)
			# sed 's/.../d' removes leading/trailing whitespace and empty lines
			if curl -sf $url | pdftotext -l 1 - - | grep -q 'Version:'; then
				curl -sf $url | pdftotext -l 1 - - | sed -n '/Summary:/,/Version:/ {s/Summary://; /Version:/q; p}'\
					| sed 's/^[[:space:]]*//;s/[[:space:]]*$//;/^[[:space:]]*$/d' | tr -s '\n'
			else
				curl -sf $url | pdftotext -l 1 - - | sed -n '/Summary:/,$ {s/Summary: //; p}'\
					| sed 's/^[[:space:]]*//;s/[[:space:]]*$//;/^[[:space:]]*$/d' | tr -s '\n'
			fi
			;;
		--version|-v)
			if curl -sf $url | pdftotext -l 1 - - | grep -q 'Version:'; then
				curl -sf $url | pdftotext -l 1 - - | grep 'Version:' | cut -d' ' -f2;
			else
				echo "This pdf doesn't have version";
			fi
			;;
		--page|-p)
			if [ -z "$3" ]; then
				curl -sf $url | pdftotext - -
			else
				curl -sf $url | pdftotext -f $3 -l $3 - -
			fi
			;;
		--entry|-e)
			# echo "Returns the -eTH entry for a pdf name"
			# echo "Usage: ./42pdf NAME/ID -e <entry>"
			echo -n "$pdf_id "
			curl -sf $url | pdftotext -l 1 - - | sed -n "2p"
			;;
		*)
			echo "Invalid option: $2"
			display_help
			exit 1
			;;
	esac
}

main() {
	# update/migrate variables
	start_id=$(cat $db_name | tail -n 1 | awk '{print $1}')
	id_batch_size=1000
	let start_id=start_id+1
	let end_id=start_id+id_batch_size
	case "$1" in
		# database changing functions
		migrate)
			migrate_database
			;;
		update)
			update_database
			;;
		update-fast)
			update_database_super_fast
			;;
		find)
			fzf_search "$@"
			;;
		pack)
			download_pack "$@"
			;;
		*)
			download_pdf "$@"
			;;
	esac
}

check_errors "$@"
main "$@"

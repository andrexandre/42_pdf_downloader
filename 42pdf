#!/bin/bash

db_name=db.txt

check_errors() {
	if ! ping -c 1 google.com &> /dev/null; then
		echo "No internet connection"
		exit 1
	fi
	if [ ! -f $db_name ] || [ ! -s $db_name ]; then
		echo "$db_name does not exist or is empty"
		echo "Clone the repo and execute 42pdf from there"
		echo "git clone https://github.com/andrexandre/42_pdf_downloader.git && cd 42_pdf_downloader"
		exit 1
	fi
	if [ -z "$1" ]; then
		echo "No argument provided. Please provide a search term"
		exit 1
	fi
}

search_and_download() {
	if [ "$1" == "-u" ] && [ "$1" == "--update" ]; then
		update_db
	fi
	pdf_id=$(grep -i "$1" $db_name | tail -n 1)
	if [ -z "$pdf_id" ]; then
		echo "No pdf called $1 found"
		exit 1
	fi
	# parse pdf variables
	pdf_name=$(echo $pdf_id | cut -d' ' -f2- | tr ' ' '_')
	pdf_id=$(echo $pdf_id | awk '{print $1}')
	url=https://cdn.intra.42.fr/pdf/pdf/$pdf_id/en.subject.pdf
	curl -sfo $pdf_name.subject.pdf $url
	if [ $? -eq 0 ]; then
		echo "Downloaded $pdf_name subject, id: $pdf_id"
	else
		echo "Failed to download $pdf_name subject, id: $pdf_id"
		exit 1
	fi
}

migrate_database() {
	updating_started=false
	if [ ! -f new_db.txt ]; then
		echo There is no file new_db.txt
		exit 1
	fi
	pdf_id=$(cat $db_name | tail -n 1 | awk '{print $1}')
	while IFS= read -r curr_line; do
		if [[ "$curr_line" == "$pdf_id" ]]; then
			updating_started=true
			echo Started updating from $pdf_id
			continue
		fi
		if [ "$updating_started" == true ]; then
			pdf_id=$(echo $curr_line | awk '{print $1}')
			url=https://cdn.intra.42.fr/pdf/pdf/$pdf_id/en.subject.pdf
			# commands to check the existance of pdf on server
			status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
			if [ "$status_code" -eq 200 ]; then
				pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
				echo "$curr_line $pdf_name" >> $db_name
			fi
			echo "Progress: $pdf_id"
		fi
	done < new_db.txt
	if [ "$updating_started" == false ]; then
		echo There is nothing to migrate
	else
		echo Everything migrated successfully
	fi
}

# VAR
# 42 pdf to db ratio: less than 2000 per month
# batch size should be good at 1000 per run (runs bimonthly)
start_id=$(cat $db_name | tail -n 1 | awk '{print $1}')
# batch size cannot be less than 10 if auto restart is active
id_batch_size=1000
let start_id=start_id+1
let end_id=start_id+id_batch_size

update_database_in_order()
{
	for (( i=start_id; i<=end_id; i++ ))
	do
		url=https://cdn.intra.42.fr/pdf/pdf/$i/en.subject.pdf
		status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
		if [ "$status_code" -eq 200 ]; then
			pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
			echo "$i $pdf_name" >> db.txt
			# auto restart
			# let end_id=i+id_batch_size
		fi
	done
}

update_database_real_fast()
{
	threads_num=50 # My pc - 50, 42 pc - 200
	seq $start_id $end_id | xargs -P $threads_num -I {} bash -c '
		url=https://cdn.intra.42.fr/pdf/pdf/{}/en.subject.pdf
		status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
		if [ "$status_code" -eq 200 ]; then
			pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
			echo "{} $pdf_name" >> db.txt
		fi
	'
	sort -n -o db.txt db.txt
}

# MAIN
check_errors "$1"
if [ "$1" == "-u" ] || [ "$1" == "--update" ]; then
	update_database_in_order
	# update_database_real_fast
elif [ "$2" == "-m" ] || [ "$1" == "--migrate" ]; then
	migrate_database
else
	search_and_download "$1"
fi

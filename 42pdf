#!/bin/bash

check_dependencies() {
	dependencies=("ping" "curl" "grep" "xargs" "sort" "tail" "head" "cut" "seq" "tr" "awk" "pdftotext")
	for cmd in "${dependencies[@]}"; do
		if ! command -v $cmd &> /dev/null; then
			echo "Command $cmd does not exist"
		fi
	done
	echo "All dependencies are installed"
	exit
}
check_dependencies
db_name=db.txt
start_id=$(cat $db_name | tail -n 1 | awk '{print $1}')

check_errors() {
	if ! ping -c 1 google.com &> /dev/null; then
		echo "No internet connection"
		exit 1
	fi
	if [ ! -f $db_name ] || [ ! -s $db_name ]; then
		echo "$db_name does not exist or is empty"
		echo "Clone the repo and execute 42pdf from there"
		echo "git clone https://github.com/andrexandre/42_pdf_downloader.git && cd 42_pdf_downloader"
		exit 1
	fi
	if [ -z "$1" ]; then
		echo "No argument provided. Please provide a search term"
		exit 1
	fi
}

search_and_download() {
	pdf_id=$(grep -i "$1" $db_name | tail -n 1)
	if [ -z "$pdf_id" ]; then
		echo "No pdf called $1 found"
		exit 1
	fi
	# parse pdf variables
	pdf_name=$(echo $pdf_id | cut -d' ' -f2- | tr ' ' '_')
	pdf_id=$(echo $pdf_id | awk '{print $1}')
	url=https://cdn.intra.42.fr/pdf/pdf/$pdf_id/en.subject.pdf
	curl -sfo $pdf_name.subject.pdf $url
	if [ $? -eq 0 ]; then
		echo "Downloaded $pdf_name subject, id: $pdf_id"
	else
		echo "Failed to download $pdf_name subject, id: $pdf_id"
		exit 1
	fi
}

migrate_database() {
	if [ ! -f new_db.txt ]; then
		echo There is no file new_db.txt
		exit 1
	fi
	updating_started=false
	# pdf_id=$(cat $db_name | tail -n 1 | awk '{print $1}')
	while IFS= read -r curr_line; do
		if [[ "$curr_line" == "$start_id" ]]; then
			updating_started=true
			echo Started updating from $start_id
			continue
		fi
		if [ "$updating_started" == true ]; then
			start_id=$(echo $curr_line | awk '{print $1}')
			url=https://cdn.intra.42.fr/pdf/pdf/$start_id/en.subject.pdf
			# commands to check the existance of pdf on server
			status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
			if [ "$status_code" -eq 200 ]; then
				pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
				echo "$curr_line $pdf_name" >> $db_name
			fi
		fi
	done < new_db.txt
	if [ "$updating_started" == false ]; then
		echo There is nothing to migrate
	else
		echo Everything migrated successfully
	fi
}

# batch size cannot be less than 10 if auto restart is active
id_batch_size=1000
let start_id=start_id+1
let end_id=start_id+id_batch_size

update_database_in_order()
{
	for (( i=start_id; i<=end_id; i++ ))
	do
		url=https://cdn.intra.42.fr/pdf/pdf/$i/en.subject.pdf
		status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
		if [ "$status_code" -eq 200 ]; then
			pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
			echo "$i $pdf_name" >> db.txt
			# auto restart
			# let end_id=i+id_batch_size
		fi
	done
}

update_database_real_fast()
{
	threads_num=50 # My pc - 50, 42 pc - 200
	seq $start_id $end_id | xargs -P $threads_num -I {} bash -c '
		url=https://cdn.intra.42.fr/pdf/pdf/{}/en.subject.pdf
		status_code=$(curl -s -f -o /dev/null -w "%{http_code}\n" --head $url)
		if [ "$status_code" -eq 200 ]; then
			pdf_name=$(curl -s -f -o - $url | pdftotext -l 1 - - | head -n 1)
			echo "{} $pdf_name" >> db.txt
		fi
	'
	sort -n -o db.txt db.txt
}

# MAIN
check_errors "$1"
if [ "$1" == "-u" ] || [ "$1" == "--update" ]; then
	update_database_in_order
	# update_database_real_fast
elif [ "$1" == "-m" ] || [ "$1" == "--migrate" ]; then
	migrate_database
elif [ "$1" == "-c" ] || [ "$1" == "--check" ]; then
	check_dependencies
else
	search_and_download "$1"
fi
